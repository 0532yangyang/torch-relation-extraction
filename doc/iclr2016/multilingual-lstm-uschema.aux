\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{NELL,yago,freebase}
\citation{limin}
\citation{toutanova2015representing}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{freebase}
\citation{yago,freebase}
\citation{nickel2015review}
\citation{rescal,DBLP:journals/corr/Garcia-DuranBUG15,bishan,transe,wang2014knowledge,lin2015learning}
\citation{socherkb}
\citation{bunescu2007learning,distant_supervision,riedel2010modeling,yao2010collective,hoffmann2011knowledge,surdeanu2012multi,min2013distant,zengdistant}
\citation{openie,etzioni2008open,resolver}
\newlabel{sec:background}{{2}{2}{Background}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background }{2}{section.2}}
\newlabel{sec:prediction}{{2.1}{2}{Relation Extraction as Link Prediction}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Relation Extraction as Link Prediction }{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Relation Extraction as Sentence Classification}{2}{subsection.2.2}}
\newlabel{seq:dist}{{2.2}{2}{Relation Extraction as Sentence Classification}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Open-Domain Relation Extraction}{2}{subsection.2.3}}
\citation{limin}
\citation{limin}
\citation{limin}
\citation{limin}
\citation{rendle2009bpr}
\citation{toutanova2015representing}
\citation{pra,pra_second,vector_pra,neelakantan2015compositional}
\citation{schein2002methods}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Examples of sentences expressing relations. Open IE patterns (italicized) consist of text ocurring between entities (bold) in a sentence.  {\bf  [[}\leavevmode {\color  {blue} todo: add extra column for open IE pattern. Also, discuss how this requires rules. instead we use deep learning.}{\bf  ]]}}}{3}{table.1}}
\newlabel{tab:patterns}{{1}{3}{Examples of sentences expressing relations. Open IE patterns (italicized) consist of text ocurring between entities (bold) in a sentence.  \todo {add extra column for open IE pattern. Also, discuss how this requires rules. instead we use deep learning.}}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Universal Schema}{3}{subsection.2.4}}
\newlabel{eq:US-prob}{{1}{3}{Universal Schema}{equation.2.1}{}}
\citation{toutanova2015representing}
\citation{collobert2011natural,KalchbrennerACL2014,kim2014convolutional}
\citation{toutanova2015representing}
\citation{lstm}
\citation{rnnmt,rnnparse}
\citation{toutanova2015representing}
\citation{toutanova2015representing}
\citation{toutanova2015representing}
\citation{xu2015classifying}
\citation{zengdistant}
\@writefile{toc}{\contentsline {section}{\numberline {3}Training a Sentence Classifier without Alignment}{4}{section.3}}
\newlabel{sec:uschema}{{3}{4}{Training a Sentence Classifier without Alignment}{section.3}{}}
\newlabel{sec:encoder}{{4}{4}{Predictions for Unseen Text Patterns}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Predictions for Unseen Text Patterns }{4}{section.4}}
\citation{limin}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Modeling Idiomatic Patterns}{5}{subsection.4.1}}
\newlabel{sec:non-comp}{{4.1}{5}{Modeling Idiomatic Patterns}{subsection.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Examples of compositional vs. idiomatic text patterns for relation extraction.}}{5}{table.2}}
\newlabel{tab:patterns2}{{2}{5}{Examples of compositional vs. idiomatic text patterns for relation extraction}{table.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Multilingual Relation Extraction with Zero Annotation}{5}{section.5}}
\newlabel{sec:multilingual}{{5}{5}{Multilingual Relation Extraction with Zero Annotation}{section.5}{}}
\citation{koehn2005europarl}
\citation{Gouws2015,luong2015bilingual,hermann2014multilingual}
\citation{mikolov2013,faruqui2014retrofitting}
\citation{mikolov2013}
\citation{transe,wang2014knowledge,lin2015learning,bishan,toutanova2015representing}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Splitting the entities in a multilingul AKBC training set into parts. We only require that sets B and D overlap. Remarkably, we can train a model for the low-resource language even if C is empty.}}{6}{table.3}}
\newlabel{tab:multilingual-corpora}{{3}{6}{Splitting the entities in a multilingul AKBC training set into parts. We only require that sets B and D overlap. Remarkably, we can train a model for the low-resource language even if C is empty}{table.3}{}}
\newlabel{sec:tie-words}{{5.1}{6}{Tied Sentence Encoders}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Tied Sentence Encoders }{6}{subsection.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments}{6}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Task}{6}{subsection.6.1}}
\citation{mccallum09:factorie:}
\citation{surdeanu2012multi}
\citation{roth2014relationfactory}
\citation{toutanova2015representing}
\citation{toutanova2015representing}
\citation{limin}
\citation{limin}
\citation{rendle2009bpr}
\newlabel{sec:results}{{6.2}{7}{Results}{subsection.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Results}{7}{subsection.6.2}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Precision, recall and F1 of English-only models on the English TAC 2013 slot-filling task. LSTM+US ensemble outperforms any single model. }}{8}{table.4}}
\newlabel{en-tac-table}{{4}{8}{Precision, recall and F1 of English-only models on the English TAC 2013 slot-filling task. LSTM+US ensemble outperforms any single model}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces F1 scores of multilingual models on the English TAC 2013 slot-filling task. Jointly embedding English and Spanish entity pairs results in higher scores on the English evaluation. }}{8}{table.5}}
\newlabel{en-es-tac-table}{{5}{8}{F1 scores of multilingual models on the English TAC 2013 slot-filling task. Jointly embedding English and Spanish entity pairs results in higher scores on the English evaluation}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Zero-shot results (F1 scores) of multilingual models on 2012 Spanish TAC KBP slot-filling task. Adding a translation dictionary improves all compositional models. Ensembling LSTM and US models performs the best. }}{8}{table.6}}
\newlabel{es-tac-table}{{6}{8}{Zero-shot results (F1 scores) of multilingual models on 2012 Spanish TAC KBP slot-filling task. Adding a translation dictionary improves all compositional models. Ensembling LSTM and US models performs the best}{table.6}{}}
\newlabel{sec:qual-anal}{{6.3}{9}{Qualitative Analysis}{subsection.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Qualitative Analysis }{9}{subsection.6.3}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Examples of the \emph  {per:children} relation discovered by the LSTM and Universal Schema. Entities are bold and patterns italicized. The LSTM can model a richer set of patterns }}{9}{table.7}}
\newlabel{tab:lstm-us-similar-rels}{{7}{9}{Examples of the \emph {per:children} relation discovered by the LSTM and Universal Schema. Entities are bold and patterns italicized. The LSTM can model a richer set of patterns}{table.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion and Future Work}{9}{section.7}}
\bibdata{sources}
\bibcite{openie}{{1}{2007}{{Banko et~al.}}{{Banko, Cafarella, Soderland, Broadhead, and Etzioni}}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces  {\bf  [[}\leavevmode {\color  {blue} todo: remove some of these examples}{\bf  ]]}. Top English patterns for a Spanish query pattern encoded using the dictionary LSTM: For each Spanish query (English translation in italics), a list of English nearest neighbors. }}{10}{table.8}}
\newlabel{tab:cross-lingual-relations}{{8}{10}{\todo {remove some of these examples}. Top English patterns for a Spanish query pattern encoded using the dictionary LSTM: For each Spanish query (English translation in italics), a list of English nearest neighbors}{table.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces The compositional models jointly embed Spanish and English words into a shared space. Example English query words (not in translation dictionary) are bold and top nearest neighbors by cosine similarity are listed for the dictionary and no ties LSTM variants. Dictionary-tied nearest neighbors are consistently more relevant to the query word than non-tied. }}{10}{table.9}}
\newlabel{joint-word}{{9}{10}{The compositional models jointly embed Spanish and English words into a shared space. Example English query words (not in translation dictionary) are bold and top nearest neighbors by cosine similarity are listed for the dictionary and no ties LSTM variants. Dictionary-tied nearest neighbors are consistently more relevant to the query word than non-tied}{table.9}{}}
\bibcite{freebase}{{2}{2008}{{Bollacker et~al.}}{{Bollacker, Evans, Paritosh, Sturge, and Taylor}}}
\bibcite{transe}{{3}{2013}{{Bordes et~al.}}{{Bordes, Usunier, Garc{\'\i }a-Dur{\'a}n, Weston, and Yakhnenko}}}
\bibcite{bunescu2007learning}{{4}{2007}{{Bunescu \& Mooney}}{{Bunescu and Mooney}}}
\bibcite{NELL}{{5}{2010}{{Carlson et~al.}}{{Carlson, Betteridge, Kisiel, Settles, Hruschka, and A}}}
\bibcite{collobert2011natural}{{6}{2011}{{Collobert et~al.}}{{Collobert, Weston, Bottou, Karlen, Kavukcuoglu, and Kuksa}}}
\bibcite{etzioni2008open}{{7}{2008}{{Etzioni et~al.}}{{Etzioni, Banko, Soderland, and Weld}}}
\bibcite{faruqui2014retrofitting}{{8}{2014}{{Faruqui et~al.}}{{Faruqui, Dodge, Jauhar, Dyer, Hovy, and Smith}}}
\bibcite{DBLP:journals/corr/Garcia-DuranBUG15}{{9}{2015}{{Garc{\'{\i }}a{-}Dur{\'{a}}n et~al.}}{{Garc{\'{\i }}a{-}Dur{\'{a}}n, Bordes, Usunier, and Grandvalet}}}
\bibcite{vector_pra}{{10}{2014}{{Gardner et~al.}}{{Gardner, Talukdar, Krishnamurthy, and Mitchell}}}
\bibcite{Gouws2015}{{11}{2015}{{Gouws et~al.}}{{Gouws, Bengio, and Corrado}}}
\bibcite{hermann2014multilingual}{{12}{2014}{{Hermann \& Blunsom}}{{Hermann and Blunsom}}}
\bibcite{lstm}{{13}{1997}{{Hochreiter \& Schmidhuber}}{{Hochreiter and Schmidhuber}}}
\bibcite{hoffmann2011knowledge}{{14}{2011}{{Hoffmann et~al.}}{{Hoffmann, Zhang, Ling, Zettlemoyer, and Weld}}}
\bibcite{KalchbrennerACL2014}{{15}{2014}{{Kalchbrenner et~al.}}{{Kalchbrenner, Grefenstette, and Blunsom}}}
\bibcite{kim2014convolutional}{{16}{2014}{{Kim}}{{}}}
\bibcite{kingma2014adam}{{17}{2015}{{Kingma \& Ba}}{{Kingma and Ba}}}
\bibcite{koehn2005europarl}{{18}{2005}{{Koehn}}{{}}}
\bibcite{pra}{{19}{2011}{{Lao et~al.}}{{Lao, Mitchell, and Cohen}}}
\bibcite{pra_second}{{20}{2012}{{Lao et~al.}}{{Lao, Subramanya, Pereira, and Cohen}}}
\bibcite{zeroshot}{{21}{2008}{{Larochelle et~al.}}{{Larochelle, Erhan, and Bengio}}}
\bibcite{lin2015learning}{{22}{2015}{{Lin et~al.}}{{Lin, Liu, Sun, Liu, and Zhu}}}
\bibcite{luong2015bilingual}{{23}{2015}{{Luong et~al.}}{{Luong, Pham, and Manning}}}
\bibcite{mccallum09:factorie:}{{24}{2009}{{McCallum et~al.}}{{McCallum, Schultz, and Singh}}}
\bibcite{mikolov2013}{{25}{2013}{{Mikolov et~al.}}{{Mikolov, Le, and Sutskever}}}
\bibcite{min2013distant}{{26}{2013}{{Min et~al.}}{{Min, Grishman, Wan, Wang, and Gondek}}}
\bibcite{distant_supervision}{{27}{2009}{{Mintz et~al.}}{{Mintz, Bills, Snow, and Jurafsky}}}
\bibcite{neelakantan2015compositional}{{28}{2015}{{Neelakantan et~al.}}{{Neelakantan, Roth, and McCallum}}}
\bibcite{rescal}{{29}{2011}{{Nickel et~al.}}{{Nickel, Tresp, and Kriegel}}}
\bibcite{nickel2015review}{{30}{2015}{{Nickel et~al.}}{{Nickel, Murphy, Tresp, and Gabrilovich}}}
\bibcite{samy}{{31}{2014}{{Norouzi et~al.}}{{Norouzi, Mikolov, Bengio, Singer, Shlens, Frome, Corrado, and Dean}}}
\bibcite{zero}{{32}{2009}{{Palatucci et~al.}}{{Palatucci, Pomerleau, Hinton, and Mitchell}}}
\bibcite{rendle2009bpr}{{33}{2009}{{Rendle et~al.}}{{Rendle, Freudenthaler, Gantner, and Schmidt-Thieme}}}
\bibcite{riedel2010modeling}{{34}{2010}{{Riedel et~al.}}{{Riedel, Yao, and McCallum}}}
\bibcite{limin}{{35}{2013}{{Riedel et~al.}}{{Riedel, Yao, McCallum, and Marlin}}}
\bibcite{roth2014relationfactory}{{36}{2014}{{Roth et~al.}}{{Roth, Barth, Chrupa{\l }a, Gropp, and Klakow}}}
\bibcite{schein2002methods}{{37}{2002}{{Schein et~al.}}{{Schein, Popescul, Ungar, and Pennock}}}
\bibcite{socherkb}{{38}{2013{a}}{{Socher et~al.}}{{Socher, Chen, Manning, and Ng}}}
\bibcite{zerosocher}{{39}{2013{b}}{{Socher et~al.}}{{Socher, Ganjoo, Manning, and Ng}}}
\bibcite{yago}{{40}{2007}{{Suchanek et~al.}}{{Suchanek, Kasneci, and Weikum}}}
\bibcite{surdeanu2012multi}{{41}{2012}{{Surdeanu et~al.}}{{Surdeanu, Tibshirani, Nallapati, and Manning}}}
\bibcite{rnnmt}{{42}{2014}{{Sutskever et~al.}}{{Sutskever, Vinyals, and Le}}}
\bibcite{toutanova2015representing}{{43}{2015}{{Toutanova et~al.}}{{Toutanova, Chen, Pantel, Poon, Choudhury, and Gamon}}}
\bibcite{rnnparse}{{44}{2014}{{Vinyals et~al.}}{{Vinyals, Kaiser, Koo, Petrov, Sutskever, and Hinton}}}
\bibcite{wang2014knowledge}{{45}{2014}{{Wang et~al.}}{{Wang, Zhang, Feng, and Chen}}}
\bibcite{xu2015classifying}{{46}{2015}{{Xu et~al.}}{{Xu, Mou, Li, Chen, Peng, and Jin}}}
\bibcite{bishan}{{47}{2015}{{Yang et~al.}}{{Yang, Yih, He, Gao, and Deng}}}
\bibcite{yao2010collective}{{48}{2010}{{Yao et~al.}}{{Yao, Riedel, and McCallum}}}
\bibcite{resolver}{{49}{2007}{{Yates \& Etzioni}}{{Yates and Etzioni}}}
\bibcite{zengdistant}{{50}{2015}{{Zeng et~al.}}{{Zeng, Liu, Chen, and Zhao}}}
\bibstyle{iclr2016_conference}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix}{13}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Details Concerning Cosine Similarity Computation}{13}{subsection.A.1}}
\newlabel{app:cosine}{{A.1}{13}{Details Concerning Cosine Similarity Computation}{subsection.A.1}{}}
\citation{mikolov2013}
\citation{toutanova2015representing}
\citation{kingma2014adam}
\newlabel{sec:data}{{A.2}{14}{Data Pre-processing}{subsection.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Data Pre-processing }{14}{subsection.A.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Generation of Cross-Lingual Tied Word Types}{14}{subsection.A.3}}
\newlabel{sec:word-tying}{{A.3}{14}{Generation of Cross-Lingual Tied Word Types}{subsection.A.3}{}}
\newlabel{sec:ds-el}{{A.4}{14}{Distant supervision and entity linking}{subsection.A.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Distant supervision and entity linking }{14}{subsection.A.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5}Open IE Pattern Normalization}{14}{subsection.A.5}}
\newlabel{sec:norm}{{A.5}{14}{Open IE Pattern Normalization}{subsection.A.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.6}Implementation and Hyperparameters}{15}{subsection.A.6}}
\newlabel{sec:details}{{A.6}{15}{Implementation and Hyperparameters}{subsection.A.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.7}Additional Qualitative Results}{15}{subsection.A.7}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Top scoring patterns for both Spanish and English given TAC relations. }}{15}{table.10}}
\newlabel{tab:top-tac-patterns}{{10}{15}{Top scoring patterns for both Spanish and English given TAC relations}{table.10}{}}
