\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{NELL,yago,freebase}
\citation{limin}
\citation{yao2013universal,vector_pra,neelakantan2015compositional,logicmfnaacl15,toutanova2015representing}
\citation{freebase}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{yago,freebase}
\citation{nickel2015review}
\citation{rescal,DBLP:journals/corr/Garcia-DuranBUG15,bishan,transe,wang2014knowledge,lin2015learning}
\citation{socherkb}
\citation{bunescu2007learning,distant_supervision,riedel2010modeling,yao2010collective,hoffmann2011knowledge,surdeanu2012multi,min2013distant,zengdistant}
\citation{openie,etzioni2008open,resolver}
\citation{limin}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Splitting the entities in a multilingual AKBC training set into parts. We only require that entities in the two corpora overlap. Remarkably, we can train a model for the low-resource language even if entities in the low-resource language do not occur in the KB. }}{2}{figure.1}}
\newlabel{tab:multilingual-corpora}{{1}{2}{Splitting the entities in a multilingual AKBC training set into parts. We only require that entities in the two corpora overlap. Remarkably, we can train a model for the low-resource language even if entities in the low-resource language do not occur in the KB}{figure.1}{}}
\newlabel{sec:background}{{2}{2}{Background}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background }{2}{section.2}}
\newlabel{sec:prediction}{{2.1}{2}{Relation Extraction as Link Prediction}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Relation Extraction as Link Prediction }{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Relation Extraction as Sentence Classification}{2}{subsection.2.2}}
\newlabel{seq:dist}{{2.2}{2}{Relation Extraction as Sentence Classification}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Open-Domain Relation Extraction}{2}{subsection.2.3}}
\newlabel{sec:openIE}{{2.3}{2}{Open-Domain Relation Extraction}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Universal Schema}{2}{subsection.2.4}}
\citation{limin}
\citation{limin}
\citation{limin}
\citation{limin}
\citation{rendle2009bpr}
\citation{toutanova2015representing}
\citation{pra,pra_second,vector_pra,neelakantan2015compositional}
\citation{limin}
\citation{schein2002methods}
\citation{toutanova2015representing}
\citation{limin}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Examples of sentences expressing relations. Context tokens (italicized) consist of the text occurring between entities (bold) in a sentence. OpenIE patterns are obtained by normalizing the context tokens using hand-coded rules. The top example expresses the per:siblings relation and the bottom two examples both express the per:cities\_of\_residence relation. }}{3}{table.1}}
\newlabel{tab:patterns}{{1}{3}{Examples of sentences expressing relations. Context tokens (italicized) consist of the text occurring between entities (bold) in a sentence. OpenIE patterns are obtained by normalizing the context tokens using hand-coded rules. The top example expresses the per:siblings relation and the bottom two examples both express the per:cities\_of\_residence relation}{table.1}{}}
\newlabel{eq:US-prob}{{1}{3}{Universal Schema}{equation.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Training a Sentence Classifier without Alignment}{3}{section.3}}
\newlabel{sec:uschema}{{3}{3}{Training a Sentence Classifier without Alignment}{section.3}{}}
\newlabel{sec:encoder}{{4}{3}{Predictions for Unseen Text Patterns}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Predictions for Unseen Text Patterns }{3}{section.4}}
\citation{collobert2011natural,KalchbrennerACL2014,kim2014convolutional}
\citation{toutanova2015representing}
\citation{lstm}
\citation{rnnmt,rnnparse}
\citation{toutanova2015representing}
\citation{toutanova2015representing}
\citation{toutanova2015representing}
\citation{xu2015classifying}
\citation{zengdistant}
\citation{limin}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Modeling Frequent Text Patterns}{4}{subsection.4.1}}
\newlabel{sec:non-comp}{{4.1}{4}{Modeling Frequent Text Patterns}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Multilingual Relation Extraction with Zero Annotation}{4}{section.5}}
\newlabel{sec:multilingual}{{5}{4}{Multilingual Relation Extraction with Zero Annotation}{section.5}{}}
\citation{zeroshot}
\citation{koehn2005europarl}
\citation{Gouws2015,luong2015bilingual,hermann2014multilingual}
\citation{mikolov2013,faruqui2014retrofitting}
\citation{mikolov2013}
\citation{transe,wang2014knowledge,lin2015learning,bishan,toutanova2015representing}
\citation{roth2014relationfactory}
\citation{angeli2014stanford}
\citation{mccallum09:factorie:}
\citation{surdeanu2012multi}
\citation{roth2014relationfactory}
\citation{surdeanu2012multi}
\newlabel{sec:tie-words}{{5.1}{5}{Tied Sentence Encoders}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Tied Sentence Encoders }{5}{subsection.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments}{5}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Task}{5}{subsection.6.1}}
\citation{toutanova2015representing}
\citation{toutanova2015representing}
\citation{limin}
\citation{limin}
\citation{rendle2009bpr}
\citation{roth2014relationfactory}
\citation{angeli2014stanford}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Precision, recall and F1 of English-only models on the English TAC 2013 slot-filling task. LSTM+USchema ensemble outperforms any single model. }}{6}{table.2}}
\newlabel{en-tac-table}{{2}{6}{Precision, recall and F1 of English-only models on the English TAC 2013 slot-filling task. LSTM+USchema ensemble outperforms any single model}{table.2}{}}
\newlabel{sec:results}{{6.2}{6}{Results}{subsection.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Results}{6}{subsection.6.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Zero-Annotation transfer learning F1 scores on 2012 Spanish TAC KBP slot-filling task. Adding a translation dictionary improves all encoder-based models. Ensembling LSTM and USchema models performs the best. }}{6}{table.3}}
\newlabel{es-tac-table}{{3}{6}{Zero-Annotation transfer learning F1 scores on 2012 Spanish TAC KBP slot-filling task. Adding a translation dictionary improves all encoder-based models. Ensembling LSTM and USchema models performs the best}{table.3}{}}
\newlabel{sec:qual-anal}{{6.3}{7}{Qualitative Analysis}{subsection.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Qualitative Analysis }{7}{subsection.6.3}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Examples of the \emph  {per:children} relation discovered by the LSTM and Universal Schema. Entities are bold and patterns italicized. The LSTM can model a richer set of patterns }}{7}{table.4}}
\newlabel{tab:lstm-us-similar-rels}{{4}{7}{Examples of the \emph {per:children} relation discovered by the LSTM and Universal Schema. Entities are bold and patterns italicized. The LSTM can model a richer set of patterns}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Top English patterns for a Spanish query pattern encoded using the dictionary LSTM: For each Spanish query (English translation in italics), a list of English nearest neighbors. }}{7}{table.5}}
\newlabel{tab:cross-lingual-relations}{{5}{7}{Top English patterns for a Spanish query pattern encoded using the dictionary LSTM: For each Spanish query (English translation in italics), a list of English nearest neighbors}{table.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{7}{section.7}}
\bibdata{sources}
\bibcite{angeli2014stanford}{\citename {Angeli \bgroup et al.\egroup }2014}
\bibcite{openie}{\citename {Banko \bgroup et al.\egroup }2007}
\bibcite{freebase}{\citename {Bollacker \bgroup et al.\egroup }2008}
\bibcite{transe}{\citename {Bordes \bgroup et al.\egroup }2013}
\bibcite{bunescu2007learning}{\citename {Bunescu and Mooney}2007}
\bibcite{NELL}{\citename {Carlson \bgroup et al.\egroup }2010}
\bibcite{collobert2011natural}{\citename {Collobert \bgroup et al.\egroup }2011}
\bibcite{etzioni2008open}{\citename {Etzioni \bgroup et al.\egroup }2008}
\bibcite{faruqui2014retrofitting}{\citename {Faruqui \bgroup et al.\egroup }2014}
\bibcite{DBLP:journals/corr/Garcia-DuranBUG15}{\citename {Garc{\'{\i }}a{-}Dur{\'{a}}n \bgroup et al.\egroup }2015}
\bibcite{vector_pra}{\citename {Gardner \bgroup et al.\egroup }2014}
\bibcite{Gouws2015}{\citename {Gouws \bgroup et al.\egroup }2015}
\bibcite{hermann2014multilingual}{\citename {Hermann and Blunsom}2014}
\bibcite{lstm}{\citename {Hochreiter and Schmidhuber}1997}
\bibcite{hoffmann2011knowledge}{\citename {Hoffmann \bgroup et al.\egroup }2011}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Example English query words (not in translation dictionary) in bold with their top nearest neighbors by cosine similarity listed for the dictionary and no ties LSTM variants. Dictionary-tied nearest neighbors are consistently more relevant to the query word than untied. }}{8}{table.6}}
\newlabel{joint-word}{{6}{8}{Example English query words (not in translation dictionary) in bold with their top nearest neighbors by cosine similarity listed for the dictionary and no ties LSTM variants. Dictionary-tied nearest neighbors are consistently more relevant to the query word than untied}{table.6}{}}
\bibcite{KalchbrennerACL2014}{\citename {Kalchbrenner \bgroup et al.\egroup }2014}
\bibcite{kim2014convolutional}{\citename {Kim}2014}
\bibcite{kingma2014adam}{\citename {Kingma and Ba}2015}
\bibcite{koehn2005europarl}{\citename {Koehn}2005}
\bibcite{pra}{\citename {Lao \bgroup et al.\egroup }2011}
\bibcite{pra_second}{\citename {Lao \bgroup et al.\egroup }2012}
\bibcite{zeroshot}{\citename {Larochelle \bgroup et al.\egroup }2008}
\bibcite{lin2015learning}{\citename {Lin \bgroup et al.\egroup }2015}
\bibcite{luong2015bilingual}{\citename {Luong \bgroup et al.\egroup }2015}
\bibcite{mccallum09:factorie:}{\citename {McCallum \bgroup et al.\egroup }2009}
\bibcite{mikolov2013}{\citename {Mikolov \bgroup et al.\egroup }2013}
\bibcite{min2013distant}{\citename {Min \bgroup et al.\egroup }2013}
\bibcite{distant_supervision}{\citename {Mintz \bgroup et al.\egroup }2009}
\bibcite{neelakantan2015compositional}{\citename {Neelakantan \bgroup et al.\egroup }2015}
\bibcite{rescal}{\citename {Nickel \bgroup et al.\egroup }2011}
\bibcite{nickel2015review}{\citename {Nickel \bgroup et al.\egroup }2015}
\bibcite{rendle2009bpr}{\citename {Rendle \bgroup et al.\egroup }2009}
\bibcite{riedel2010modeling}{\citename {Riedel \bgroup et al.\egroup }2010}
\bibcite{limin}{\citename {Riedel \bgroup et al.\egroup }2013}
\bibcite{logicmfnaacl15}{\citename {Rocktaschel \bgroup et al.\egroup }2015}
\bibcite{roth2014relationfactory}{\citename {Roth \bgroup et al.\egroup }2014}
\bibcite{schein2002methods}{\citename {Schein \bgroup et al.\egroup }2002}
\bibcite{socherkb}{\citename {Socher \bgroup et al.\egroup }2013}
\bibcite{yago}{\citename {Suchanek \bgroup et al.\egroup }2007}
\bibcite{surdeanu2012multi}{\citename {Surdeanu \bgroup et al.\egroup }2012}
\bibcite{rnnmt}{\citename {Sutskever \bgroup et al.\egroup }2014}
\bibcite{toutanova2015representing}{\citename {Toutanova \bgroup et al.\egroup }2015}
\bibcite{rnnparse}{\citename {Vinyals \bgroup et al.\egroup }2014}
\bibcite{wang2014knowledge}{\citename {Wang \bgroup et al.\egroup }2014}
\bibcite{xu2015classifying}{\citename {Xu \bgroup et al.\egroup }2015}
\bibcite{bishan}{\citename {Yang \bgroup et al.\egroup }2015}
\bibcite{yao2010collective}{\citename {Yao \bgroup et al.\egroup }2010}
\bibcite{yao2013universal}{\citename {Yao \bgroup et al.\egroup }2013}
\bibcite{resolver}{\citename {Yates and Etzioni}2007}
\bibcite{zengdistant}{\citename {Zeng \bgroup et al.\egroup }2015}
\bibstyle{naaclhlt2016}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix}{10}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Additional Qualitative Results}{10}{subsection.A.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Details Concerning Cosine Similarity Computation}{10}{subsection.A.2}}
\newlabel{app:cosine}{{A.2}{10}{Details Concerning Cosine Similarity Computation}{subsection.A.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Top scoring patterns for both Spanish (top) and English (bottom) given query TAC relations. }}{10}{table.7}}
\newlabel{tab:top-tac-patterns}{{7}{10}{Top scoring patterns for both Spanish (top) and English (bottom) given query TAC relations}{table.7}{}}
\newlabel{sec:ds-el}{{A.3}{10}{Data Pre-processing, Distant Supervision and Extraction Pipeline}{subsection.A.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Data Pre-processing, Distant Supervision and Extraction Pipeline }{10}{subsection.A.3}}
\citation{mikolov2013}
\citation{toutanova2015representing}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Generation of Cross-Lingual Tied Word Types}{11}{subsection.A.4}}
\newlabel{sec:word-tying}{{A.4}{11}{Generation of Cross-Lingual Tied Word Types}{subsection.A.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5}Open IE Pattern Normalization}{11}{subsection.A.5}}
\newlabel{sec:norm}{{A.5}{11}{Open IE Pattern Normalization}{subsection.A.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.6}Implementation and Hyperparameters}{11}{subsection.A.6}}
\newlabel{sec:details}{{A.6}{11}{Implementation and Hyperparameters}{subsection.A.6}{}}
