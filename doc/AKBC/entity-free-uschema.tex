\documentclass{article} % For LaTeX2e
\usepackage{naaclhlt2016}
\usepackage{times}
\usepackage{latexsym}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amsmath,amsthm,amsfonts}
\usepackage{multirow}
\usepackage{xspace}
\usepackage{tikz}
\usetikzlibrary{shapes,backgrounds,patterns}
\usepackage{graphicx}
\graphicspath{ {images/} }


\newcommand{\Prob}{\mathbb{P}}
\newcommand{\todo}[1]{{\bf [[}\textcolor{blue}{ todo: #1}{\bf ]]}}
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

% named as such because `\arg1' apparently isn't valid
\newcommand{\argOne}{\emph{arg1}\xspace}
\newcommand{\argTwo}{\emph{arg2}\xspace}

\newcommand{\citep}[1]{\cite{#1}}
\newcommand{\citet}[1]{\newcite{#1}}



\title{Universal Schema Without Entity Embeddings}

\author{Patrick Verga \& Andrew McCallum \\
    College of Information and Computer Sciences\\
    University of Massachusetts Amherst\\
    % Amherst, MA 01002, USA \\
    \texttt{\{pat, mccallum\}@cs.umass.edu} \\
}

\begin{document}


\maketitle

\begin{abstract}
Universal schema jointly embeds knowledge bases and textual patterns to reason about entities and relations for automatic knowledge base construction and information extraction.
In the past, entity pairs and relations were represented as learned vectors whose compatibility was determined by a scoring function.
However, this leads to cold-start problems where the model is unable to reason about entity pairs and text patterns unseen at train time.
Recently, compositional Universal Schema was proposed to address generalization to unseen text patterns.
In this work we take the next step of removing explicit entity pair representations.
Instead of learning vector representations for each entity pair in our training set, we treat an entity pair as a function of its relation.
In this paper, we experiment with several aggregation functions and demonstrate that we can perform inference using only learned relation representations.
\end{abstract}



% intro + background
\input{intro}

% methods
\input{model}

% results
\input {results}

% conclusion
\section{Conclusion}
In this paper we explore the extension of Universal Schema that forgoes exlicit entity pair representations for an aggregatation function over mentions.
This extension allows us to handle all entity pairs - whether they were seen at train time or not - and also gives us a trivial connection to the provenance which made the prediction.
We present prelimanary findings for several aggregation functions including those that act on the individual relation level as well as those that learn to pool over groups of relations.
These prelimenary experiments were carried out on a fairly small dataset, we plan to test this on a much larger data set in the future.

In the future we plan two further extensions to this work.
The first is to improve the aggregation function with a query specific attention that will be able to proporitonally pool all evidence while simultaneously producing a weighting over provenanes.
The second extension will be to incorporate this work with existing work on Compositional Universal Schema creating a fully generalizable Universal Schema able to predict on all text.


\subsubsection*{Acknowledgments}

\bibliography{sources}
\bibliographystyle{naaclhlt2016}

\newpage
%\appendix
%\input{appendix}




\end{document}
